{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**ry-c++-log** /home/tim/git/robotics-course_tim/rai/rai/ry/ry.cpp:init_LogToPythonConsole:34(0) initializing ry log callback\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import libry as ry\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- REAL WORLD configuration, which is attached to the physics engine\n",
    "# accessing this directly would be cheating!\n",
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../../scenarios/challenge.g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<libry.CameraViewSensor at 0x7fe6e0192b30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = RealWorld.simulation(ry.SimulatorEngine.bullet, True)\n",
    "S.addSensor(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- MODEL WORLD configuration, this is the data structure on which you represent\n",
    "# what you know about the world and compute things (controls, contacts, etc)\n",
    "C = ry.Config()\n",
    "#D = C.view() #rather use the ConfiguratioViewer below\n",
    "C.addFile(\"../../scenarios/pandasTable.g\")\n",
    "C.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- the following is the simulation loop\n",
    "tau = .01\n",
    "\n",
    "for t in range(300):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "            [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "\n",
    "    #some good old fashioned IK\n",
    "    C.setJointState(q) #set your robot model to match the real q\n",
    "    [y,J] = C.evalFeature(ry.FS.position, [\"R_gripper\"])\n",
    "    vel = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0])) @ [0.,0.,-1e-1];\n",
    "\n",
    "    #send velocity controls to the simulation\n",
    "    S.step(vel, tau, ry.ControlMode.velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- teleport an object by messing with the RealWorld\n",
    "f = RealWorld.getFrame(\"obj1\")\n",
    "f.setPosition([0,0,2])\n",
    "S.setState(RealWorld.getFrameState())\n",
    "S.step([], tau, ry.ControlMode.none) #this makes the change actually appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- get the state of the simulation\n",
    "[X,Vel] = S.getState()\n",
    "# and set it again\n",
    "S.setState(X,Vel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doing things relative to an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new frame to the MODEL configuration\n",
    "# (Perception will later have to do exactly this: add perceived objects to the model)\n",
    "obj = C.addFrame(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set frame parameters, associate a shape to the frame, \n",
    "obj.setPosition([.8,0,1.5])\n",
    "obj.setQuaternion([1,0,.5,0])\n",
    "obj.setShape(ry.ST.capsule, [.2,.02])\n",
    "obj.setColor([1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyquaternion'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bd486f2b2f20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyquaternion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuaternion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyquaternion'"
     ]
    }
   ],
   "source": [
    "#-- the following is the simulation loop\n",
    "tau = .01\n",
    "\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "for t in range(300):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "            [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "\n",
    "    #some good old fashioned IK\n",
    "    C.setJointState(q) #set your robot model to match the real q\n",
    "    #print(C.getFrameNames())\n",
    "    marker = C.addFrame(\"marker\",\"object\")\n",
    "    marker.setRelativeQuaternion(Quaternion)\n",
    "    [y,J] = C.evalFeature(ry.FS.poseDiff, [\"R_gripper\", \"marker\"])\n",
    "    vel = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0])) @ (-y);\n",
    "\n",
    "    #send velocity controls to the simulation\n",
    "    S.step(vel, tau, ry.ControlMode.velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could you align the gripper for a proper grasp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=0\n",
    "V=0\n",
    "C=0\n",
    "RealWorld=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct inverse Kinematics with multiple objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import libry as ry\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<libry.CameraViewSensor at 0x7f852aca4e30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../../scenarios/challenge.g\")\n",
    "\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.bullet, True)\n",
    "S.addSensor(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = ry.Config()\n",
    "C.addFile(\"../../scenarios/pandasTable.g\")\n",
    "C.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = .01\n",
    "\n",
    "for t in range(300):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "            [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "\n",
    "    C.setJointState(q) #set your robot model to match the real q\n",
    "    #evaluate a first feature\n",
    "    [y1,J1] = C.evalFeature(ry.FS.position, [\"R_gripper\"])\n",
    "    #redefine y1 to become the desired change-of-value (\"error\" or \"residual\"); here just a constant velocity\n",
    "    y1 = np.array([0.,0.,-1e-1])\n",
    "    #you can multiply y1 and J1 here with some number, to increase the importance of the first feature\n",
    "    \n",
    "    #evaluate a second feature\n",
    "    [y2,J2] = C.evalFeature(ry.FS.scalarProductYZ, [\"R_gripper\",\"world\"])\n",
    "    #redefine y2 to become the desired change-of-value (\"error\" or \"residual\"); here by subtracting the target\n",
    "    y2 = [1.] - y2\n",
    "    #you can multiply y2 and J2 here with some number, to increase the importance of the second feature\n",
    "\n",
    "    #stack all tasks\n",
    "    y = np.block([y1, y2])\n",
    "    J = np.block([[J1],[J2]])\n",
    "    \n",
    "    vel = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0])) @ y;\n",
    "\n",
    "    #send velocity controls to the simulation\n",
    "    S.step(vel, tau, ry.ControlMode.velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
