{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** INFO:/home/tim/git/robotics-course_tim/rai/rai/Core/util.cpp:initCmdLine:602(1) ** cmd line arguments: 'rai-pybind -python'\n",
      "** INFO:/home/tim/git/robotics-course_tim/rai/rai/Core/util.cpp:initCmdLine:606(1) ** run path: '/home/tim/git/robotics-course_tim/course3-Simulation/04-opencv'\n",
      "**ry-c++-log** /home/tim/git/robotics-course_tim/rai/rai/ry/ry.cpp:init_LogToPythonConsole:34(0) initializing ry log callback** INFO:/home/tim/git/robotics-course_tim/rai/rai/Core/graph.cpp:initParameters:1365(1) ** parsed parameters:\n",
      "{python}\n",
      "\n",
      "\n",
      "\n",
      "4.5.3\n",
      "** INFO:/home/tim/git/robotics-course_tim/rai/rai/ry/ry.cpp:init_LogToPythonConsole:34(0) initializing ry log callback\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import libry as ry\n",
    "import time\n",
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Add REAL WORLD configuration and camera\n",
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../../scenarios/ex03_redball.g\")\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.bullet, True)\n",
    "S.addSensor(\"camera\")\n",
    "\n",
    "C = ry.Config()\n",
    "C.addFile('../../scenarios/pandasTable.g')\n",
    "D = C.view()\n",
    "cameraFrame = C.frame(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the focal length\n",
    "f = 0.895\n",
    "f = f * 360.\n",
    "#the relative pose of the camera\n",
    "# pcl.setRelativePose('d(-90 0 0 1) t(-.08 .205 .115) d(26 1 0 0) d(-1 0 1 0) d(6 0 0 1) ')\n",
    "fxfypxpy = [f, f, 320., 180.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = C.addFrame(\"object\")\n",
    "obj.setPosition([.3,0.3,.71])\n",
    "#obj.setQuaternion([1,0,1,0])\n",
    "obj.setShape(ry.ST.sphere, [.1])\n",
    "obj.setColor([1,1,0])\n",
    "obj.setContact(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 (30, 98, 7)\n",
      "** KOMO::run solver:sparse collisions:1 x-dim:420 T:30 k:2 phases:1 stepsPerPhase:30 tau:0.166667  #timeSlices:32 #totalDOFs:420 #frames:3136\n",
      "** optimization time:0.345795 (kin:0.01105 coll:0.227261 feat:0.052378 newton: 0.02695) setJointStateCount:38\n",
      "   sos:100.052 ineq:0.000154054 eq:0.00323932\n"
     ]
    }
   ],
   "source": [
    "# we want to optimize a single step (1 phase, 1 step/phase, duration=1, k_order=1)\n",
    "komo = C.komo_path(1.,30, 5., True)\n",
    "komo.addObjective([1.], ry.FS.positionDiff, [\"R_gripper\", \"object\"], ry.OT.sos, [1e2])\n",
    "komo.addObjective([.5,1.], ry.FS.position, [\"R_gripper\"], ry.OT.eq, [1e2],[-.0,-.0,-.01], order=2)\n",
    "komo.addObjective([], ry.FS.distance, [\"R_gripper\", \"object\"], ry.OT.ineq, [1e2],[-.0])\n",
    "\n",
    "print(komo.getT(),komo.getPathFrames().shape)\n",
    "\n",
    "komo.optimize()\n",
    "#komo.getReport()\n",
    "#V = komo.view_play(False, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for frame,tau in zip(komo.getPathFrames(),komo.getPathTau()):\n",
    "    time.sleep(tau)\n",
    "    \n",
    "    C.setFrameState(frame)\n",
    "\n",
    "    q= C.getJointState()\n",
    "\n",
    "    #send position to the simulation\n",
    "    S.step(q, tau, ry.ControlMode.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_background(depth,rgb,background=None):\n",
    "    if background is None:\n",
    "        background = depth\n",
    "    \n",
    "    diff = background - depth\n",
    "\n",
    "    mask = cv.inRange(diff, 0.1,100)\n",
    "\n",
    "    _,thres = cv.threshold(diff, 0.1, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    if len(diff)>0: cv.imshow('OPENCV - mask', thres)\n",
    "\n",
    "    filtered_mask = np.zeros(mask.shape, np.uint8)\n",
    "    \n",
    "    # find contours\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) > 0:\n",
    "        # find largest contour\n",
    "        largest, idx = 0., None\n",
    "        for i, c in enumerate(contours):\n",
    "            # remove noise\n",
    "            if c.shape[0] < 10: continue\n",
    "            if cv.contourArea(c) > largest:\n",
    "                largest = cv.contourArea(c)\n",
    "                idx = i\n",
    "        cv.drawContours(rgb, contours[idx], -1, (255, 255, 255), -1)\n",
    "    if len(rgb)>0: cv.imshow('OPENCV - rgb', cv.cvtColor(rgb, cv.COLOR_BGR2RGB))\n",
    "       \n",
    "\n",
    "    # mask = cv.inRange(diff,\n",
    "    return background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_99903/3617279452.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcameraFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetPointCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mbackground\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrack_background\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbackground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_99903/2382050423.py\u001b[0m in \u001b[0;36mtrack_background\u001b[0;34m(depth, rgb, background)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mlargest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OPENCV - rgb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not NoneType"
     ]
    }
   ],
   "source": [
    "points = []\n",
    "tau = .01\n",
    "background = None\n",
    "for t in range(400):\n",
    "    time.sleep(0.03)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "        [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "        points = S.depthData2pointCloud(depth, fxfypxpy)\n",
    "        cameraFrame.setPointCloud(points, rgb)\n",
    "\n",
    "        background = track_background(depth,rgb,background)\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    S.step([], tau, ry.ControlMode.none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os._exit(0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "151e6003ef3448e9dad8ac998da13fd7f08f405b4e0b7cacbbaf31913d5c8a90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('rai_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
